

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Models &mdash; Detecting Real vs AI Generated Images Dec 2024 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=dba8473a"></script>
      <script src="_static/doctools.js?v=888ff710"></script>
      <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Features" href="features.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Detecting Real vs AI Generated Images
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="main_pipeline.html">Main Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="features.html">Features</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#models.AdvancedNeuralNetwork"><code class="docutils literal notranslate"><span class="pre">AdvancedNeuralNetwork</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#models.AdvancedNeuralNetwork.forward"><code class="docutils literal notranslate"><span class="pre">AdvancedNeuralNetwork.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#models.AdvancedNeuralNetwork.training"><code class="docutils literal notranslate"><span class="pre">AdvancedNeuralNetwork.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#models.FusedDataset"><code class="docutils literal notranslate"><span class="pre">FusedDataset</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#models.FusedDataset.X"><code class="docutils literal notranslate"><span class="pre">FusedDataset.X</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#models.FusedDataset.y"><code class="docutils literal notranslate"><span class="pre">FusedDataset.y</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#models.FusedDataset.__len__"><code class="docutils literal notranslate"><span class="pre">FusedDataset.__len__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#models.FusedDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">FusedDataset.__getitem__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#models.evaluate_and_save_metrics"><code class="docutils literal notranslate"><span class="pre">evaluate_and_save_metrics()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#models.objective"><code class="docutils literal notranslate"><span class="pre">objective()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#models.train_and_save_models"><code class="docutils literal notranslate"><span class="pre">train_and_save_models()</span></code></a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Detecting Real vs AI Generated Images</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="models">
<h1>Models<a class="headerlink" href="#models" title="Permalink to this heading"></a></h1>
<p>Training and testing SVM, Neural Net, and XGBoost on the extracted embeddings.</p>
<span class="target" id="module-models"></span><dl class="py class">
<dt class="sig sig-object py" id="models.AdvancedNeuralNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">models.</span></span><span class="sig-name descname"><span class="pre">AdvancedNeuralNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#AdvancedNeuralNetwork"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.AdvancedNeuralNetwork" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Defines an advanced neural network architecture with Batch Normalization and Dropout.</p>
<dl class="py method">
<dt class="sig sig-object py" id="models.AdvancedNeuralNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#AdvancedNeuralNetwork.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.AdvancedNeuralNetwork.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the forward pass of the neural network.</p>
<p>This function passes the input <cite>x</cite> through the sequential layers of the network. The layers consist
of fully connected layers, Batch Normalization, ReLU activation, and Dropout (for regularization).
The final output is generated by the last fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The input tensor that will be passed through the network.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the neural network after passing through all layers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="models.AdvancedNeuralNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#models.AdvancedNeuralNetwork.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="models.FusedDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">models.</span></span><span class="sig-name descname"><span class="pre">FusedDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#FusedDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.FusedDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code></p>
<p>Custom Dataset for handling fused features and labels.</p>
<p>This class is used to create a PyTorch Dataset that combines features and labels, allowing for easy
handling and loading of the data during model training or evaluation. The dataset stores the input features
and labels as tensors, which are then accessed by indexing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>numpy.ndarray</em><em> or </em><em>torch.Tensor</em>) – A 2D array or tensor containing the input features for each sample.</p></li>
<li><p><strong>labels</strong> (<em>numpy.ndarray</em><em> or </em><em>torch.Tensor</em>) – A 1D array or tensor containing the labels for each sample.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="models.FusedDataset.X">
<span class="sig-name descname"><span class="pre">X</span></span><a class="headerlink" href="#models.FusedDataset.X" title="Permalink to this definition"></a></dt>
<dd><p>A tensor containing the input features.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="models.FusedDataset.y">
<span class="sig-name descname"><span class="pre">y</span></span><a class="headerlink" href="#models.FusedDataset.y" title="Permalink to this definition"></a></dt>
<dd><p>A tensor containing the labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.FusedDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#FusedDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.FusedDataset.__len__" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of samples in the dataset.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.FusedDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#FusedDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.FusedDataset.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Retrieves the feature and label pair for the sample at the specified index.</p>
</dd></dl>

<p class="rubric">Example</p>
<p>features = np.random.rand(100, 10)  # 100 samples, 10 features each
labels = np.random.randint(0, 2, size=100)  # Binary labels for each sample
dataset = FusedDataset(features, labels)
print(len(dataset))  # Prints the number of samples in the dataset.
sample = dataset[0]  # Retrieves the first sample’s features and label.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="models.evaluate_and_save_metrics">
<span class="sig-prename descclassname"><span class="pre">models.</span></span><span class="sig-name descname"><span class="pre">evaluate_and_save_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_nn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#evaluate_and_save_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.evaluate_and_save_metrics" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the model on the test set and save evaluation metrics.</p>
<p>This function evaluates the given model on the provided test set (<cite>X_test</cite> and <cite>y_test</cite>) by calculating
various performance metrics including accuracy, precision, recall, F1 score, and AUROC. It also generates
a classification report. The metrics are saved as a JSON file in the specified output directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>sklearn.base.BaseEstimator</em><em> or </em><em>torch.nn.Module</em>) – The trained model to be evaluated.</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – The name of the model, which will be used for saving the metrics.</p></li>
<li><p><strong>X_test</strong> (<em>numpy.ndarray</em><em> or </em><em>torch.Tensor</em>) – The feature matrix for the test set.</p></li>
<li><p><strong>y_test</strong> (<em>numpy.ndarray</em><em> or </em><em>torch.Tensor</em>) – The true labels for the test set.</p></li>
<li><p><strong>output_dir</strong> (<em>str</em>) – The directory where the evaluation metrics will be saved.</p></li>
<li><p><strong>is_nn</strong> (<em>bool</em><em>, </em><em>optional</em>) – A flag indicating if the model is a neural network. Defaults to False.</p></li>
<li><p><strong>device</strong> (<em>str</em><em>, </em><em>optional</em>) – The device (‘cpu’ or ‘cuda’) to use for inference with neural networks. Defaults to ‘cpu’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>evaluate_and_save_metrics(model, “MyModel”, X_test, y_test, “path/to/output”)
# Evaluates the model and saves the metrics to the specified output directory.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="models.objective">
<span class="sig-prename descclassname"><span class="pre">models.</span></span><span class="sig-name descname"><span class="pre">objective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trial</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_valid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_valid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#objective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.objective" title="Permalink to this definition"></a></dt>
<dd><p>Objective function for Optuna to optimize neural network hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trial</strong> (<em>optuna.trial.Trial</em>) – Optuna trial object.</p></li>
<li><p><strong>X_train</strong> (<em>np.ndarray</em>) – Training features.</p></li>
<li><p><strong>X_valid</strong> (<em>np.ndarray</em>) – Validation features.</p></li>
<li><p><strong>y_train</strong> (<em>np.ndarray</em>) – Training labels.</p></li>
<li><p><strong>y_valid</strong> (<em>np.ndarray</em>) – Validation labels.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – Device to run the model on.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Validation accuracy.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="models.train_and_save_models">
<span class="sig-prename descclassname"><span class="pre">models.</span></span><span class="sig-name descname"><span class="pre">train_and_save_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/models.html#train_and_save_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#models.train_and_save_models" title="Permalink to this definition"></a></dt>
<dd><p>Trains and saves models using SVM, XGBoost, and a Neural Network, with hyperparameter optimization using Optuna.</p>
<p>This function standardizes the training data, trains three different machine learning models (SVM, XGBoost, and Neural Network)
using hyperparameter optimization with Optuna, and saves the models and evaluation metrics.
For each model, the best hyperparameters are determined via Optuna, the model is trained on the training data,
and performance metrics are computed and saved.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<em>numpy.ndarray</em>) – The feature matrix for the training set.</p></li>
<li><p><strong>X_test</strong> (<em>numpy.ndarray</em>) – The feature matrix for the test set.</p></li>
<li><p><strong>y_train</strong> (<em>numpy.ndarray</em>) – The true labels for the training set.</p></li>
<li><p><strong>y_test</strong> (<em>numpy.ndarray</em>) – The true labels for the test set.</p></li>
<li><p><strong>output_dir</strong> (<em>str</em>) – Directory where models, metrics, and other outputs will be saved.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
train_and_save_models(X_train, X_test, y_train, y_test, “path/to/output”)
# Trains the models and saves the results to the output directory.</p>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="features.html" class="btn btn-neutral float-left" title="Features" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, By: Nashrah Haque, Lavanya Pushparaj, &amp; Thien an Pham.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>